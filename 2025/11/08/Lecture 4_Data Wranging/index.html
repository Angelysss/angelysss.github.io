<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Lecture 4_Data Wranging | None</title><meta name="author" content="Angelysss"><meta name="copyright" content="Angelysss"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Overview 本视频的核心论题是“数据整理”（Data Wrangling）。视频将“数据整理”定义为将数据从一种格式转换为另一种格式的任何过程 [00:07]，例如从原始的、庞杂的日志文件（Log File）中提取出有价值的统计图表或摘要信息。视频的结论是，通过“管道”（Pipe）操作符将一系列小巧、专一的命令行工具（如 grep, sed, awk, sort, unique 等）组合起">
<meta property="og:type" content="article">
<meta property="og:title" content="Lecture 4_Data Wranging">
<meta property="og:url" content="http://example.com/2025/11/08/Lecture%204_Data%20Wranging/index.html">
<meta property="og:site_name" content="None">
<meta property="og:description" content="Overview 本视频的核心论题是“数据整理”（Data Wrangling）。视频将“数据整理”定义为将数据从一种格式转换为另一种格式的任何过程 [00:07]，例如从原始的、庞杂的日志文件（Log File）中提取出有价值的统计图表或摘要信息。视频的结论是，通过“管道”（Pipe）操作符将一系列小巧、专一的命令行工具（如 grep, sed, awk, sort, unique 等）组合起">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/avatar.jpg">
<meta property="article:published_time" content="2025-11-08T06:49:12.140Z">
<meta property="article:modified_time" content="2025-11-08T07:00:34.183Z">
<meta property="article:author" content="Angelysss">
<meta property="article:tag" content="Note">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Lecture 4_Data Wranging",
  "url": "http://example.com/2025/11/08/Lecture%204_Data%20Wranging/",
  "image": "http://example.com/img/avatar.jpg",
  "datePublished": "2025-11-08T06:49:12.140Z",
  "dateModified": "2025-11-08T07:00:34.183Z",
  "author": [
    {
      "@type": "Person",
      "name": "Angelysss",
      "url": "https://github.com/angelysss"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2025/11/08/Lecture%204_Data%20Wranging/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          const mediaQueryDark = window.matchMedia('(prefers-color-scheme: dark)')
          const mediaQueryLight = window.matchMedia('(prefers-color-scheme: light)')

          if (theme === undefined) {
            if (mediaQueryLight.matches) activateLightMode()
            else if (mediaQueryDark.matches) activateDarkMode()
            else {
              const hour = new Date().getHours()
              const isNight = hour <= 7 || hour >= 21
              isNight ? activateDarkMode() : activateLightMode()
            }
            mediaQueryDark.addEventListener('change', () => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else {
            theme === 'light' ? activateLightMode() : activateDarkMode()
          }
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"pagination":{"enable":false,"hitsPerPage":8},"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'medium_zoom',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Lecture 4_Data Wranging',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"></head><body><div id="web_bg" style="background-image: url(/img/background.png);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/avatar.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">7</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">1</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/top.png);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">None</span></a><a class="nav-page-title" href="/"><span class="site-name">Lecture 4_Data Wranging</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> List</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">Lecture 4_Data Wranging</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-11-08T06:49:12.140Z" title="发表于 2025-11-08 14:49:12">2025-11-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-11-08T07:00:34.183Z" title="更新于 2025-11-08 15:00:34">2025-11-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Missing-Semester/">Missing Semester</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">7.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>24分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h3 id="overview"><a class="markdownIt-Anchor" href="#overview"></a> Overview</h3>
<p>本视频的核心论题是“数据整理”（Data Wrangling）。视频将“数据整理”定义为将数据从一种格式转换为另一种格式的任何过程 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=7">00:07</a>]，例如从原始的、庞杂的日志文件（Log File）中提取出有价值的统计图表或摘要信息。视频的结论是，通过“管道”（Pipe）操作符将一系列小巧、专一的命令行工具（如 <code>grep</code>, <code>sed</code>, <code>awk</code>, <code>sort</code>, <code>unique</code> 等）组合起来，可以构建出极其强大的数据处理流程。这种“流式处理”的范式，使得用户无需编写复杂的自定义脚本，就能在命令行中完成对海量数据（甚至是二进制数据）的即时分析、转换和聚合，从而获得可操作的洞察。</p>
<hr />
<h3 id="按照主题来梳理"><a class="markdownIt-Anchor" href="#按照主题来梳理"></a> 按照主题来梳理</h3>
<h4 id="主题一什么是数据整理-data-wrangling-与数据源准备"><a class="markdownIt-Anchor" href="#主题一什么是数据整理-data-wrangling-与数据源准备"></a> 主题一：什么是数据整理 (Data Wrangling) 与数据源准备</h4>
<p>“数据整理”（Data Wrangling）这个词听起来可能有些奇怪，但它的基本思想非常普遍：你手头的数据格式并不是你最终想要的格式，你需要对其进行转换 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=7">00:07</a>]。这个过程并不仅仅指代像图像格式转换这样的操作，它更常用于处理文本文件、日志文件等 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=18">00:18</a>]。例如，你可能希望将一个巨大的日志文件转换为一个图表，或者从中提取出关键的统计数据。任何将数据从一种表现形式转换为另一种表现形式的过程，都可以被称为“数据整理” [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=28">00:28</a>]。</p>
<p><strong>数据整理的常见形式：管道 (Pipe)</strong></p>
<p>在之前的课程中，我们已经见识过简单的数据整理形式，那就是每当你使用“管道”操作符（<code>|</code>）时 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=42">00:42</a>]。管道允许你将一个程序的输出，作为另一个程序的输入。这本身就是一种数据转换。在本次讲座中，我们将探索一些更高级、更实用的数据整理方法。</p>
<p><strong>准备数据源：系统日志 (System Log)</strong></p>
<p>要进行任何数据整理，你首先需要一个数据源 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=66">01:06</a>]。讲座中选择的数据源是一个运行在荷兰的服务器上的系统日志 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=77">01:17</a>]。这台服务器上运行着一个标准的 Linux 日志记录守护进程（Daemon），称为 <code>systemd</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=90">01:30</a>]。在 Linux 系统上，有一个 <code>journalctl</code> 命令可以用来查看系统日志 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=97">01:37</a>]。</p>
<p>当我们运行这个命令时，会立即面临第一个挑战：数据量极其庞大 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=116">01:56</a>]。这个日志记录了服务器上发生的所有事情，可以追溯到很久以前，包含了海量的信息。</p>
<p><strong>首次过滤：使用 <code>grep</code> 缩小范围</strong></p>
<p>面对海量的日志，第一步是缩小范围，只关注我们感兴趣的部分。<code>grep</code> 命令是这种场景下的首选工具 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=133">02:13</a>]。</p>
<ul>
<li>
<p><strong>目标：</strong> 讲座的目标是分析 <code>SSH</code> (Secure Shell，安全外壳协议) 的登录日志。<code>SSH</code> 是一种通过命令行远程访问计算机的方式 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=139">02:19</a>]。当你将一台服务器暴露在公共互联网上时，一个普遍现象是，全世界会有非常多的人（或自动化程序）试图连接到你的服务器，尝试猜测密码并接管它 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=151">02:31</a>]。</p>
</li>
<li>
<p><strong>操作：</strong> 我们可以通过管道将 <code>journalctl</code> 的输出传递给 <code>grep</code>，并筛选包含“SSH”关键字的行：<code>journalctl | grep ssh</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=159">02:39</a>]。</p>
</li>
<li>
<p><strong>问题：</strong> 即使这样过滤，<code>SSH</code> 相关的日志量依然非常大，难以直接查看 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=176">02:56</a>]。</p>
</li>
</ul>
<p><strong>远程处理：在服务器端进行过滤</strong></p>
<p>讲座接着指出了一个重要的优化点。如果我们按照 <code>journalctl | grep ...</code> 的方式在本地执行，整个流程是这样的：</p>
<ol>
<li>
<p><code>journalctl</code> 命令（在远程服务器上运行）产生完整的、海量的日志数据。</p>
</li>
<li>
<p>这些海量数据通过网络传输到我们本地的机器上。</p>
</li>
<li>
<p>本地机器上的 <code>grep</code> 命令对这些数据进行过滤 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=209">03:29</a>]。</p>
</li>
</ol>
<p>这个过程非常浪费，因为我们只关心其中极小的一部分数据，却传输了所有数据 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=221">03:41</a>]。一个更高效的方法是利用 <code>SSH</code> 本身的能力，让服务器完成过滤工作，只把过滤后的结果发送给我们。</p>
<ul>
<li>
<p><strong>优化操作：</strong> 我们可以通过 <code>ssh</code> 命令，告诉远程服务器执行一个完整的“管道命令”，然后再将结果传回本地。命令大致如下：<code>ssh [server_name] &quot;journalctl | grep 'disconnected from'&quot; | less</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=225">03:45</a>]。</p>
</li>
<li>
<p><strong>流程解析：</strong> 这条命令告诉 <code>ssh</code>，在远程服务器上执行 <code>&quot;journalctl | grep 'disconnected from'&quot;</code>。服务器只将匹配“disconnected from”的行（这是我们真正关心的登录失败信息）通过网络发送回来 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=243">04:03</a>]。</p>
</li>
<li>
<p><strong>本地分页：</strong> <code>| less</code>：<code>less</code> 是一个“分页器”（Pager）程序 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=247">04:07</a>]。它能接收大量的文本输入，但只在屏幕上显示一页内容，允许你上下滚动（使用 <code>Ctrl+U</code> / <code>Ctrl+D</code>）和退出（<code>q</code>），而不是让海量信息快速滚过屏幕 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=259">04:19</a>]。</p>
</li>
</ul>
<p><strong>本地缓存：创建 <code>ssh.log</code> 文件</strong></p>
<p>在演示中，由于网络延迟或 <code>grep</code> 缓冲，实时获取数据可能很慢 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=277">04:37</a>]。为了教学演示的流畅性，讲师采取了一个实用技巧：他事先运行了上述的远程过滤命令，并将结果重定向（<code>&gt;</code>）保存到了一个本地文件 <code>ssh.log</code> 中 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=326">05:26</a>]。</p>
<ul>
<li>
<p><code>ssh [server_name] &quot;journalctl | grep 'disconnected from'&quot; &gt; ssh.log</code></p>
</li>
<li>
<p>这个操作创建了一个本地的数据快照（Cache）。这样做的好处是，在后续的所有分析步骤中，我们不再需要依赖缓慢的网络连接去实时获取数据，只需从本地的 <code>ssh.log</code> 文件中读取即可 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=345">05:45</a>]。</p>
</li>
<li>
<p>我们现在可以使用 <code>cat ssh.log</code> 来读取文件内容，并通过管道将其传递给其他工具，这与从实时日志中读取的效果完全相同，但速度快得多 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=367">06:07</a>]。我们现在有了一个包含大量“disconnected from invalid user …”日志行的数据集，准备好进行下一步处理 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=355">05:55</a>]。</p>
</li>
</ul>
<h4 id="主题二使用-sed-和正则表达式-regular-expressions-提取关键信息"><a class="markdownIt-Anchor" href="#主题二使用-sed-和正则表达式-regular-expressions-提取关键信息"></a> 主题二：使用 <code>sed</code> 和正则表达式 (Regular Expressions) 提取关键信息</h4>
<p>现在我们有了一个 <code>ssh.log</code> 文件，里面装满了我们感兴趣的日志行，但这些行仍然包含大量我们不需要的“垃圾信息”，比如日期、主机名、进程 ID 等 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=406">06:46</a>]。我们真正关心的，只是那些被用于尝试登录的“用户名”。为了从每行中精确提取出这部分信息，我们将使用一个强大的工具：<code>sed</code>（Stream Editor，流编辑器）[<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=410">06:50</a>]。</p>
<p><strong><code>sed</code>：流编辑器</strong></p>
<p><code>sed</code> 是一种流编辑器，它逐行读取输入流，对每一行应用你提供的编辑命令，然后输出修改后的行 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=439">07:19</a>]。你可以把它想象成一个自动化的“查找与替换”工具，但它的功能远不止于此，它本身是一种图灵完备的编程语言 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=446">07:26</a>]。</p>
<ul>
<li>
<p>sed 的基本用法：替换</p>
<p>sed 最常见的用途是执行替换操作，其基本语法是 s/search/replace/（s 代表 substitute，替换）[07:36]。</p>
</li>
<li>
<p>首次尝试：移除行首的无用信息</p>
<p>我们观察到，所有日志行的开头都有一长串我们不关心的信息（如 Jan 01 10:00:00 servername sshd[12345]: ），直到“disconnected from”这个短语出现。我们可以尝试把这之前的所有内容都删除掉 [07:46]。</p>
<p>命令：cat ssh.log | sed ‘s/.*disconnected from //’ [08:33]</p>
<p>这个命令的意思是：查找（s/）“任意数量的任意字符（.*）”加上“disconnected from ”（注意有个空格），并将其替换（/）为“空字符串”（//）。</p>
</li>
</ul>
<p><strong>核心工具：正则表达式 (Regular Expressions)</strong></p>
<p>上面命令中的 <code>.*</code> 是什么意思？这就是“正则表达式”（Regular Expression，简称 Regex）[<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=533">08:53</a>]。正则表达式是一种用来描述和匹配文本模式的强大语言，你会在命令行的各种数据整理工作中频繁地使用它 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=544">09:04</a>]。</p>
<ul>
<li>
<p><strong>Regex 基础语法点：</strong></p>
<ul>
<li>
<p><code>.</code> (点): 匹配“任意单个字符” [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=575">09:35</a>]。</p>
</li>
<li>
<p><code>*</code> (星号): 匹配“零个或多个”前一个字符 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=582">09:42</a>]。</p>
</li>
<li>
<p><code>.*</code> (点星): 这两个组合起来，表示“匹配零个或多个任意字符”，这是非常常用但也很危险的模式。</p>
</li>
<li>
<p><code>+</code> (加号): 匹配“一个或多个”前一个字符 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=612">10:12</a>]。</p>
</li>
<li>
<p><code>[]</code> (方括号): 字符集。匹配方括号中的任意一个字符。例如 <code>[ab]</code> 匹配 ‘a’ 或 ‘b’ [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=619">10:19</a>]。</p>
</li>
<li>
<p><code>()</code> (圆括号): 分组。将多个字符组合成一个单元，以便对其应用量词（如 <code>*</code> 或 <code>+</code>），或者用于“捕获” [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=702">11:42</a>]。</p>
</li>
<li>
<p><code>|</code> (竖线): 或 (Alternation)。匹配竖线任意一边的表达式。例如 <code>(ab|bc)</code> 匹配 “ab” 或 “bc” [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=776">12:56</a>]。</p>
</li>
<li>
<p><code>?</code> (问号): 匹配“零个或一个”前一个字符 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=976">16:16</a>]。</p>
</li>
<li>
<p><code>^</code> (脱字符): 锚点。匹配一行的“开头” [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1034">17:14</a>]。</p>
</li>
<li>
<p><code>$</code> (美元符): 锚点。匹配一行的“结尾” [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1034">17:14</a>]。</p>
</li>
</ul>
</li>
</ul>
<p><strong>Regex 的陷阱：贪婪匹配 (Greedy Matching)</strong></p>
<p>在使用 <code>.*</code> 时，我们很快遇到了一个问题。假设某个黑客尝试使用一个奇特的用户名，比如 <code>user_disconnected from_admin</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=900">15:00</a>]。</p>
<ul>
<li>
<p><strong>问题：</strong> <code>sed 's/.*disconnected from //'</code> 会如何表现？</p>
</li>
<li>
<p><strong>答案：</strong> 正则表达式默认是“贪婪的”（Greedy）。<code>.*</code> 会尽可能多地匹配字符，直到匹配到_最后_一个“disconnected from” [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=909">15:09</a>]。在这个例子中，它会连同用户名中的 <code>user_</code> 和第一个 <code>disconnected from</code> 一起匹配并删除，导致我们提取出错误的信息（<code>_admin</code>）甚至完全删除了用户名 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=923">15:23</a>]。</p>
</li>
<li>
<p><strong>解决方案：</strong> 使用“非贪婪”匹配。通过在 <code>*</code> 或 <code>+</code> 后面加一个 <code>?</code>（例如 <code>.*?</code>）[<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1350">22:30</a>]。<code>.*?</code> 的意思是“匹配任意字符，但尽可能少地匹配”，在它找到第一个“disconnected from”时就会停止。</p>
</li>
</ul>
<p><strong>进阶技巧：使用捕获组 (Capture Groups) 精确提取</strong></p>
<p>仅仅删除行首信息是不够的，日志行的末尾（如 IP 地址、端口号等）也是我们不想要的。与其“删除”不要的东西，不如“提取”我们想要的东西。这就要用到正则表达式的“捕获组”。</p>
<ul>
<li>
<p><strong>捕获组 (<code>()</code>):</strong> 在正则表达式中，用圆括号 <code>()</code> 括起来的部分被称为“捕获组” [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1131">18:51</a>]。匹配引擎会“记住”这部分匹配到的文本。</p>
</li>
<li>
<p><strong>反向引用 (<code>\1</code>, <code>\2</code>):</strong> 在 <code>sed</code> 的“替换”部分，我们可以使用 <code>\1</code>, <code>\2</code> 等来引用第一个、第二个捕获组所“记住”的内容 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1175">19:35</a>]。</p>
</li>
<li>
<p>构建模式： 讲师现场构建了一个非常复杂的正则表达式，用来匹配整行日志。</p>
<p>^.<em>?from (invalid |authenticating )?user (.</em>?) [0-9.]+ port [0-9]+.*$</p>
<p>这个模式的大致意思是：</p>
<ol>
<li>
<p><code>^.*?from</code>: 从行首开始，非贪婪地匹配到 &quot;from &quot;。</p>
</li>
<li>
<p><code>(invalid |authenticating )?</code>: 匹配 &quot;invalid &quot; 或 &quot;authenticating &quot;，这部分是可选的（<code>?</code>）。这是第 1 个捕获组。</p>
</li>
<li>
<p><code>user</code> : 匹配 &quot;user &quot;。</p>
</li>
<li>
<p><code>(.*?)</code>: <strong>(核心)</strong> 非贪婪地匹配任意字符，这就是我们想要的用户名。这是第 2 个捕获组。</p>
</li>
<li>
<p><code>[0-9\.]+ port [0-9]+</code>: 匹配空格、IP 地址（由数字和点组成）、&quot; port &quot;、端口号。</p>
</li>
<li>
<p><code>.*$</code>: 匹配直到行尾的</p>
</li>
</ol>
</li>
<li>
<p>执行提取：</p>
<p>cat ssh.log | sed -E ‘s/^.<em>?from (invalid |authenticating )?user (.</em>?) [0-9.]+ port [0-9]+.*$/\2/’</p>
<ul>
<li>
<p><strong><code>-E</code></strong>：这个参数很重要，它告诉 <code>sed</code> 使用“扩展正则表达式”语法（Modern Syntax），这样我们就不必在 <code>()</code>, <code>+</code>, <code>|</code> 等特殊字符前加反斜杠 <code>\</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=732">12:12</a>]。</p>
</li>
<li>
<p><strong><code>s/...(模式).../\2/</code></strong>：这里是关键。我们将匹配到的_整行_（<code>...模式...</code>）替换为 <code>\2</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1181">19:41</a>]——也就是我们的第 2 个捕获组，即用户名。</p>
</li>
</ul>
</li>
<li>
<p><strong>结果：</strong> 执行这个命令后，输出不再是完整的日志行，而是一个长长的、只有用户名的列表。</p>
</li>
</ul>
<p><strong>调试 Regex：使用可视化工具</strong></p>
<p>讲师强调，这种复杂的正则表达式很难一次性写对，而且非常难以阅读 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1206">20:06</a>]。在实际工作中，你应该使用“正则表达式调试器”（Regex Debugger）[<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1218">20:18</a>]。这些是在线工具（如 <code>regex101.com</code>），你可以把你的正则表达式和测试文本粘贴进去，它会高亮显示哪些部分被匹配了，每个捕获组捕获了什么内容 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1264">21:04</a>]，这对于调试至关重要。</p>
<p><strong>Regex 的边界：</strong></p>
<p>讲师还展示了一个例子：匹配 Email 地址的正则表达式。一个简单的版本（<code>[a-z0-9_.]+@[a-z0-9\.]+</code>）看起来可行，但其实漏洞百出 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1564">26:04</a>]。而一个真正“符合标准”的 Email 匹配表达式，其复杂度是常人无法阅读和理解的 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1620">27:00</a>]。这引出了一个重要教训：<strong>不要用正则表达式去解析结构化数据</strong>，比如 HTML 或 JSON [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1649">27:29</a>]。你应该使用专门的解析器（Parser）。Regex 适合的是像日志这样的“半结构化”或非结构化文本。</p>
<h4 id="主题三聚合数据-aggregating-data-sort-unique-和-awk"><a class="markdownIt-Anchor" href="#主题三聚合数据-aggregating-data-sort-unique-和-awk"></a> 主题三：聚合数据 (Aggregating Data) - <code>sort</code>, <code>unique</code>, 和 <code>awk</code></h4>
<p>通过 <code>sed</code> 和正则表达式，我们成功地将一个 <code>ssh.log</code> 文件（包含约 198,000 行日志）转换成了一个只有用户名的列表 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1688">28:08</a>]。这个列表本身仍然不是有用的信息，它太长了，我们无法直接从中获得洞察。我们需要对数据进行“聚合”（Aggregate）。</p>
<p><strong><code>wc -l</code>：行计数</strong></p>
<p>首先，我们用 <code>wc -l</code>（Word Count - lines）命令来统计行数，确认我们处理的数据量 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1688">28:08</a>]。结果显示有 198,000 行，即 198,000 次登录尝试。</p>
<p><strong><code>sort</code> 和 <code>unique -c</code>：统计重复项</strong></p>
<p>我们想知道的是：哪些用户名被尝试的次数最多？这需要一个三步组合：<code>sort</code> -&gt; <code>unique</code> -&gt; <code>sort</code>。</p>
<ol>
<li>
<p>sort (第一次)</p>
<p>cat usernames.list | sort</p>
<p>sort 命令将输入的每一行按字母顺序排序 [29:05]。这是使用 unique 命令的前提。</p>
</li>
<li>
<p>unique -c</p>
<p>cat usernames.list | sort | unique -c</p>
<p>unique 命令会检查已排序的输入，并“合并”所有连续的重复行，只保留一个。</p>
<p>而 -c（count）参数是它的“超级能力”：它不仅合并重复行，还会在每行前面加上该行重复出现的次数 [29:37]。</p>
<ul>
<li>
<p><strong>输入 (已排序):</strong></p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">admin</span><br><span class="line">admin</span><br><span class="line">root</span><br><span class="line">root</span><br><span class="line">root</span><br><span class="line">user</span><br></pre></td></tr></table></figure>
</li>
<li>
<p><strong>输出 (<code>unique -c</code>):</strong></p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2 admin</span><br><span class="line">3 root</span><br><span class="line">1 user</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>现在，我们的数据变成了 <code>[次数] [用户名]</code> 这样的格式。这个列表仍然很长（约 24,000 行），但已经从“原始数据”变成了“统计数据” [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1813">30:13</a>]。</p>
</li>
<li>
<p>sort -n (第二次)</p>
<p>cat usernames.list | sort | unique -c | sort -n</p>
<p>我们想知道的是“次数最多”的，所以我们对 unique -c 的输出再进行一次排序。</p>
<p>关键参数是 -n（numeric），它告诉 sort 按照“数字”大小来排序，而不是默认的“字母”顺序 [30:26]。如果不加 -n，10000 会排在 2 的前面（因为 “1” &lt; “2”）。</p>
<p>默认情况下，sort -n 是升序（Ascending）排列，即最小的数字在最前面，最大的在最后面。</p>
</li>
<li>
<p>tail：获取Top N</p>
<p>… | sort -n | tail -n 10</p>
<p>tail 命令用于显示输入的最后几行。-n 10 表示我们只想看最后 10 行 [30:58]。</p>
<p>由于我们是升序排列的，最后 10 行就是我们想要的“Top 10”（尝试次数最多的 10 个用户名）。</p>
</li>
</ol>
<p><strong>最终成果：可操作的洞察</strong></p>
<p>至此，我们通过一个命令链条（Pipeline）得到了一个清晰、有价值的列表 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1874">31:14</a>]：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">11000 root</span><br><span class="line">4000  123456</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>这个结果告诉我们，有 11,000 次登录尝试是用的 <code>root</code> 用户名，4,000 次用的是 <code>123456</code>。这立刻给了我们一个可操作的建议：在服务器上禁止 <code>root</code> 用户通过 <code>SSH</code> 登录 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1898">31:38</a>]。我们成功地从 20 万行原始日志中，提取出了“知识”。</p>
<p><strong><code>awk</code>：强大的列处理器</strong></p>
<p>接下来，讲座引入了另一个极其强大的工具：<code>awk</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1985">33:05</a>]。</p>
<ul>
<li>
<p><strong><code>sed</code> vs <code>awk</code>:</strong> 如果说 <code>sed</code> 的强项是处理“整行文本”（替换），那么 <code>awk</code> 的强项就是处理“列数据”（Columnar Data）。</p>
</li>
<li>
<p><code>awk</code> 默认使用空格或制表符将每一行分割成若干“列”（Fields）。</p>
</li>
<li>
<p><code>{print $2}</code>: 在 <code>awk</code> 的语言中，<code>$0</code> 代表整行，<code>$1</code> 代表第 1 列，<code>$2</code> 代表第 2 列 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2006">33:26</a>]。</p>
</li>
<li>
<p>应用：</p>
<p>… | sort -n | tail -n 10 | awk ‘{print $2}’</p>
<p>在我们得到的 [次数] [用户名] 列表后，如果我们只想要用户名列表（去掉次数），我们可以用 awk 轻松实现：{print $2} 表示“只打印第 2 列”。</p>
</li>
</ul>
<p><strong><code>paste</code>：合并行</strong></p>
<p>… | awk ‘{print $2}’ | paste -s -d,</p>
<p>paste 是一个用于“粘贴”行的工具。</p>
<ul>
<li>
<p><code>-s</code> (serial): 将所有输入行合并成_一行_ [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2012">33:32</a>]。</p>
</li>
<li>
<p><code>-d,</code> (delimiter): 使用逗号（<code>,</code>）作为分隔符 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2012">33:32</a>]。</p>
</li>
<li>
<p><strong>结果：</strong> <code>root,123456,admin,...</code> 我们得到了一个逗号分隔的 Top 10 用户名列表，可以直接用在邮件或配置文件中 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2036">33:56</a>]。</p>
</li>
</ul>
<p><strong><code>awk</code> 作为编程语言</strong></p>
<p><code>awk</code> 不仅仅是一个列提取工具，它也是一个完整的编程语言 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2040">34:00</a>]。</p>
<ul>
<li>
<p>过滤： 我们可以用 awk 进行复杂的过滤。</p>
<p>awk ‘$1 == 1’：只打印第 1 列（次数）等于 1 的行。</p>
<p>awk ‘<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn><mtext> </mtext><msup><mi mathvariant="normal">/</mi><mi>c</mi></msup><mi mathvariant="normal">.</mi><mo>∗</mo><mi>e</mi></mrow><annotation encoding="application/x-tex">2 ~ /^c.*e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mspace nobreak"> </span><span class="mord"><span class="mord">/</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">c</span></span></span></span></span></span></span></span><span class="mord">.</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathdefault">e</span></span></span></span>/’：只打印第 2 列（用户名）匹配正则表达式（~）^c.*e$（以 ‘c’ 开头，以 ‘e’ 结尾）的行 [35:12]。</p>
</li>
<li>
<p>状态处理： awk 拥有 BEGIN 和 END 模块 [37:07]。</p>
<p>awk ‘BEGIN { rows = 0 } $1 == 1 { rows++ } END { print rows }’</p>
<p>这个命令展示了 awk 的编程能力 [37:27]：</p>
<ol>
<li>
<p><code>BEGIN { rows = 0 }</code>: 在处理任何行之前，初始化一个变量 <code>rows</code> 为 0。</p>
</li>
<li>
<p><code>$1 == 1 { rows++ }</code>: 对于每一行，如果第 1 列等于 1，则将 <code>rows</code> 变量加 1。</p>
</li>
<li>
<p>END { print rows }: 在处理完所有行之后，打印 rows 变量的最终值。</p>
<p>这个 awk 命令自己就实现了 grep | wc -l 的功能，展示了其进行状态化处理的能力 [37:40]。</p>
</li>
</ol>
</li>
</ul>
<h4 id="主题四更多高级工具与二进制数据整理"><a class="markdownIt-Anchor" href="#主题四更多高级工具与二进制数据整理"></a> 主题四：更多高级工具与二进制数据整理</h4>
<p>讲座的最后部分，展示了管道（Pipeline）思想可以扩展到多么强大的地步，甚至包括算术运算、统计、绘图和二进制数据。</p>
<p><strong><code>bc</code>：命令行计算器</strong></p>
<p><code>bc</code> 是一个“任意精度计算器”，它可以从标准输入读取数学表达式并计算结果 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2318">38:38</a>]。</p>
<ul>
<li>
<p><strong>场景：</strong> 我们想计算所有“被多次尝试”的登录（即次数 &gt; 1）的总次数。</p>
</li>
<li>
<p><strong>流程：</strong></p>
<ol>
<li>
<p><code>... | unique -c | awk '$1 != 1 {print $1}'</code>: 我们得到一个数字列表（所有大于 1 的登录次数）。</p>
</li>
<li>
<p><code>... | paste -s -d+</code>: 使用 <code>paste</code> 将这个列表转换成一个长长的、用 <code>+</code> 连接的字符串，例如 <code>11000+4000+...</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2399">39:59</a>]。</p>
</li>
<li>
<p><code>... | bc -l</code>: 将这个数学表达式管道给 <code>bc</code>，<code>bc</code> 会计算出总和 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2407">40:07</a>]。</p>
</li>
</ol>
</li>
<li>
<p><strong>启示：</strong> 我们把“统计数字”转换成了“数学表达式文本”，再把这个文本交给另一个工具 <code>bc</code> 来执行计算。这是数据整理思想的又一次灵活运用。</p>
</li>
</ul>
<p><strong><code>R</code> 和 <code>gnuplot</code>：统计与绘图</strong></p>
<ul>
<li>
<p><code>R</code>：<code>R</code> 是一种专门用于统计分析的编程语言。我们可以将数据流直接导入 <code>R</code>，以获得更复杂的统计摘要（中位数、均值、四分位数等）[<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2444">40:44</a>]。</p>
</li>
<li>
<p><code>gnuplot</code>：这是一款命令行绘图工具。讲师展示了如何将 Top 5 的数据（用户名和次数）直接导入 <code>gnuplot</code>，在命令行中生成一个直方图（Histogram）[<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2521">42:01</a>]。</p>
</li>
<li>
<p><strong>启示：</strong> 命令行数据整理的终点不一定是文本，它可以是统计报告，甚至是可视化图表 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2553">42:33</a>]。</p>
</li>
</ul>
<p><strong><code>xargs</code>：将输入行转换为参数</strong></p>
<p><code>xargs</code> 是一个“粘合剂”工具，它解决了一个长期存在的问题：管道（<code>|</code>）传递的是“标准输入”（stdin），但很多命令（如 <code>rm</code>, <code>cp</code>, <code>mv</code>）希望从“命令行参数”（command-line arguments）中获取输入。<code>xargs</code> 的作用就是：读取标准输入中的每一行，并将这些行作为参数附加到另一个命令后面执行 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2619">43:39</a>]。</p>
<ul>
<li>
<p><strong>场景：</strong> 讲师的电脑上安装了很多个版本的 Rust 编译器（<code>rustup toolchain list</code>）[<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2633">43:53</a>]。他想删除所有 2019 年的“nightly”版本。</p>
</li>
<li>
<p><strong>流程：</strong></p>
<ol>
<li>
<p><code>rustup toolchain list | grep nightly | grep 2019</code>: 筛选出所有 2019 年的 nightly 版本。</p>
</li>
<li>
<p><code>... | sed 's/ (default)//'</code>: 用 <code>sed</code> 清理掉多余的文本。</p>
</li>
<li>
<p><code>... | xargs rustup toolchain uninstall</code>: <code>xargs</code> 读取清理后的工具链名称列表（每行一个），然后执行 <code>rustup toolchain uninstall [name1] [name2] [name3] ...</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2716">45:16</a>]。</p>
</li>
</ol>
</li>
<li>
<p><strong>启示：</strong> <code>xargs</code> 极大地扩展了管道的能力，使我们能够将“生成列表”的命令（如 <code>find</code>, <code>grep</code>）与“处理参数”的命令（如 <code>rm</code>, <code>uninstall</code>）连接起来。</p>
</li>
</ul>
<p><strong>终极形态：二进制数据整理</strong></p>
<p>管道不仅能处理文本，它本质上传输的是“字节流”（Byte Stream）。讲座的最后一个例子，展示了一个令人惊叹的、处理音视频和图像的二进制数据管道。</p>
<ul>
<li>
<p><strong>工具：</strong></p>
<ul>
<li>
<p><code>ffmpeg</code>：音视频编解码的瑞士军刀 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2768">46:08</a>]。</p>
</li>
<li>
<p><code>convert</code>：ImageMagick 套件中的图像处理工具 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2821">47:01</a>]。</p>
</li>
<li>
<p><code>gzip</code> / <code>gunzip</code>：压缩和解压缩工具 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2839">47:19</a>]。</p>
</li>
<li>
<p><code>tee</code>：T 型管道，将输入同时发送到“标准输出”和“文件” [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2855">47:35</a>]。</p>
</li>
<li>
<p><code>display</code>：图像显示工具。</p>
</li>
</ul>
</li>
<li>
<p><strong>“大满贯”管道流程 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2775">46:15</a>] - [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2888">48:08</a>]：</strong></p>
<ol>
<li>
<p><code>ffmpeg ... -i /dev/video0 ... -f image2pipe -</code>: <code>ffmpeg</code> 从摄像头（<code>/dev/video0</code>）抓取一帧图像，将其编码为图像格式，并输出到“标准输出”（stdout）。</p>
</li>
<li>
<p><code>| convert - -colorspace gray -</code>: <code>convert</code> 从“标准输入”（stdin）读取该图像，将其转换为灰度图，再输出到 stdout。</p>
</li>
<li>
<p><code>| gzip</code>: <code>gzip</code> 将灰度图像数据流进行压缩，输出到 stdout。</p>
</li>
<li>
<p><code>| ssh [server_name] &quot;gunzip | tee copy.png&quot;</code>: 压缩后的图像流通过 <code>ssh</code> 发送到远程服务器。服务器上的 <code>gunzip</code> 将其解压，<code>tee</code> 将解压后的图像流保存为文件 <code>copy.png</code>，_同时_再将其原样输出到 stdout（即传回本地）。</p>
</li>
<li>
<p><code>| display -</code>: 本地机器接收到从 <code>ssh</code> 返回的图像流，并使用 <code>display</code> 将其显示在屏幕上。</p>
</li>
</ol>
</li>
<li>
<p><strong>结果：</strong> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2888">48:08</a>] 一条命令完成了：本地拍照 -&gt; 灰度处理 -&gt; 压缩 -&gt; 上传服务器 -&gt; 服务器保存副本 -&gt; 传回本地 -&gt; 本地显示。</p>
</li>
<li>
<p><strong>结论：</strong> 这个看似“愚蠢”的例子完美地展示了 UNIX 哲学的力量：任何程序的输入输出都可以被重定向和连接，无论是文本还是二进制数据，无论是本地进程还是跨网络传输 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=2923">48:43</a>]。</p>
</li>
</ul>
<hr />
<h3 id="框架-心智模型-framework-mindset"><a class="markdownIt-Anchor" href="#框架-心智模型-framework-mindset"></a> 框架 &amp; 心智模型 (Framework &amp; Mindset)</h3>
<h4 id="框架一unix-哲学之管道与过滤器-the-unix-philosophy-pipeline-and-filters"><a class="markdownIt-Anchor" href="#框架一unix-哲学之管道与过滤器-the-unix-philosophy-pipeline-and-filters"></a> 框架一：UNIX 哲学之“管道与过滤器” (The UNIX Philosophy: “Pipeline and Filters”)</h4>
<p>本视频是“UNIX 哲学”的一次完美实践教学。其核心思想不是掌握某一个工具，而是掌握一种组合工具的框架。这个框架可以分解为三个核心原则：</p>
<ol>
<li>
<p>“做好一件事” (Do One Thing and Do It Well):</p>
<p>视频中出现的每一个工具 (grep, sed, awk, sort, unique, wc, bc, xargs)，都不是一个试图解决所有问题的庞大软件 [35:59]。相反，它们都是小巧、简单、功能专一的程序：</p>
<ul>
<li>
<p><code>grep</code> 只负责过滤行。</p>
</li>
<li>
<p><code>sort</code> 只负责排序行。</p>
</li>
<li>
<p><code>unique</code> 只负责去重和计数。</p>
</li>
<li>
<p>awk 只负责处理列。</p>
<p>这种“单一职责”的特性使得它们非常健壮、易于理解和维护。</p>
</li>
</ul>
</li>
<li>
<p>“一切皆文本流” (Everything is a Text Stream):</p>
<p>这些工具之间如何协作？它们约定了一个极其简单且通用的“接口”：面向行的文本流（Line-oriented Text Stream）。grep 的输出（文本行）可以直接被 sort 理解；sort 的输出（排序后的文本行）可以被 unique 理解；unique 的输出（带计数的文本行）又可以被 awk 或 sort -n 理解。这种以“换行符”分隔的纯文本流，是这些工具得以组合的通用语言。讲座的最后一个例子甚至将其推广到“字节流”，展示了这种思想的普适性 [48:43]。</p>
</li>
<li>
<p>“组合的力量：管道” (The Power of Composition: The Pipe):</p>
<p>如果说上述工具是“乐高积木”，那么“管道”操作符（|）就是连接积木的“榫卯” [00:42]。管道的魔力在于，它将左侧命令的“标准输出”（stdout）与右侧命令的“标准输入”（stdin）无缝连接起来。</p>
<p>这种连接能力是“涌现式”的：</p>
<ul>
<li>
<p><code>sort</code> + <code>unique -c</code> + <code>sort -n</code> 组合起来，涌现出了一个全新的功能：“频率统计工具”。</p>
</li>
<li>
<p>awk + paste + bc 组合起来，涌现出了一个全新的功能：“列数据求和工具”。</p>
<p>你不需要编写任何新的代码，只需将这些小工具按正确的顺序组合，就能创造出一个“超级工具”来解决你当前的问题 [42:41]。</p>
</li>
</ul>
</li>
</ol>
<p><strong>心智模型：迭代式的数据流处理 (Iterative Dataflow Processing)</strong></p>
<p>这个框架导向了一种“迭代式”的工作流。讲师在解决“分析日志”这个大问题时，并没有试图一步登天写出一条包含 10 个组件的命令。他的心智模型是：</p>
<ol>
<li>
<p><strong>启动数据流：</strong> <code>journalctl</code> 或 <code>cat ssh.log</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=367">06:07</a>]。让数据先“流动”起来。</p>
</li>
<li>
<p><strong>第一级处理（过滤）：</strong> <code>... | grep ssh</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=133">02:13</a>]。先砍掉大部分噪音，得到一个“半成品”。</p>
</li>
<li>
<p><strong>检查半成品：</strong> <code>... | less</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=247">04:07</a>]。看看现在的数据长什么样？哦，格式还是不对。</p>
</li>
<li>
<p><strong>第二级处理（提取）：</strong> <code>... | sed 's/.../\2/'</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1181">19:41</a>]。从半成品中提取出“精华”（用户名）。</p>
</li>
<li>
<p><strong>检查精华：</strong> <code>... | less</code> 或 <code>... | wc -l</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1688">28:08</a>]。现在我们有了一个精华列表，但太多了，需要聚合。</p>
</li>
<li>
<p><strong>第三级处理（聚合）：</strong> <code>... | sort | unique -c</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1764">29:24</a>]。将精华列表转换为“统计列表”。</p>
</li>
<li>
<p><strong>第四级处理（排序）：</strong> <code>... | sort -n</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1826">30:26</a>]。对统计列表进行排序。</p>
</li>
<li>
<p><strong>最终呈现（裁剪）：</strong> <code>... | tail -n 10</code> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1858">30:58</a>]。只看我们最关心的 Top 10 结果。</p>
</li>
</ol>
<p>这个“处理 -&gt; 检查 -&gt; 再处理”的迭代循环，是命令行数据整理的精髓。它允许你将一个模糊的、复杂的数据分析问题，拆解成一系列清晰、简单、可验证的“数据转换步骤”。每一步的输出都是下一步的输入，数据像水一样在管道中流动，经过每一级“过滤器”的处理，最终得到你想要的“纯净水”。</p>
<h4 id="框架二正则表达式-regular-expressions-描述文本的领域特定语言"><a class="markdownIt-Anchor" href="#框架二正则表达式-regular-expressions-描述文本的领域特定语言"></a> 框架二：正则表达式 (Regular Expressions) - 描述文本的“领域特定语言”</h4>
<p>正则表达式在视频中占据了核心地位，它本身也构成了一套强大的心智模型。它是一种“领域特定语言”（Domain-Specific Language, DSL），专门用于“描述文本模式”。</p>
<p><strong>心智模型：从“指令式”到“声明式” (Imperative vs. Declarative)</strong></p>
<ul>
<li>
<p><strong>指令式 (Imperative):</strong> 如果不用 Regex，要提取用户名，你可能需要用 Python 写一个循环：<code>for char in line:</code>，然后设置一堆状态变量，<code>if char == 'u' and next_char == 's': ...</code>。你是在告诉计算机“如何一步步地做”（How）。</p>
</li>
<li>
<p>声明式 (Declarative): 正则表达式（s/…(模式)…/\2/）则是“声明式”的 [08:53]。你是在向 sed 引擎“描述你想要的东西”（What）：</p>
<p>“我要的模式是：以from开头，中间可能有invalid，然后是user，接着是我要捕获的用户名 (.*?)，最后是IP地址和端口。请把匹配到的整行替换成我捕获的用户名。”</p>
<p>你只负责描述模式，sed 内部的 Regex 引擎会负责高效地执行匹配。</p>
</li>
</ul>
<p><strong>心智模型：解构模式 (Deconstructing Patterns)</strong></p>
<p>要掌握 Regex，你需要学会用“元字符”（Metacharacters）的积木来思考：</p>
<ol>
<li>
<p><strong>原子 (Atoms) / 字符类 (Character Classes):</strong> 构成模式的最小单位。</p>
<ul>
<li>
<p><strong>字面量：</strong> <code>a</code>, <code>b</code>, <code>1</code> 就代表它们自己。</p>
</li>
<li>
<p><strong>元字符：</strong> <code>.</code>（任何字符）[<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=575">09:35</a>], <code>\d</code>（数字）, <code>\s</code>（空白）。</p>
</li>
<li>
<p>集合： [abc] (a或b或c), [0-9] (0到9) [10:19]。</p>
<p>这是你描述“某个位置应该是什么样”的基础。</p>
</li>
</ul>
</li>
<li>
<p><strong>量词 (Quantifiers):</strong> 描述“重复”。</p>
<ul>
<li>
<p><code>*</code> (零或多个) [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=582">09:42</a>], <code>+</code> (一或多个) [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=612">10:12</a>], <code>?</code> (零或一个) [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=976">16:16</a>]。</p>
</li>
<li>
<p><strong>贪婪 vs. 非贪婪：</strong> 这是 Regex 中最关键的心智模型之一。默认量词是“贪婪的”（Greedy），<code>.*</code> 会尽可能多地“吃掉”字符 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=900">15:00</a>]。而 <code>.*?</code> 是“非贪婪的”（Non-greedy），它会尽可能少地“吃掉”字符 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1350">22:30</a>]。理解这一点是避免 Regex 陷阱的关键。</p>
</li>
</ul>
</li>
<li>
<p><strong>锚点 (Anchors):</strong> 描述“位置”。</p>
<ul>
<li>
<p><code>^</code> (行首) 和 <code>$</code> (行尾) [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1034">17:14</a>]。</p>
</li>
<li>
<p>讲师强调使用锚点（<code>^...$</code>）来匹配整行是一个好习惯 [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1060">17:40</a>]，这能防止你的模式意外地匹配到“行的中间某部分”，尤其是在处理可能包含“恶意输入”（Adversarial Input）的数据时。</p>
</li>
</ul>
</li>
<li>
<p><strong>分组与捕获 (Grouping &amp; Capturing):</strong></p>
<ul>
<li>
<p><code>()</code> (圆括号) 是 Regex 的“超级能力” [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1131">18:51</a>]。</p>
</li>
<li>
<p><strong>功能一：分组。</strong> <code>(ab|cd)+</code> 表示 <code>ab</code> 或 <code>cd</code> 可以重复多次。</p>
</li>
<li>
<p><strong>功能二：捕获。</strong> 引擎会“记住”圆括号内匹配到的内容，存入编号的“缓冲区”（<code>\1</code>, <code>\2</code>）[<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1175">19:35</a>]。</p>
</li>
<li>
<p>这使得 Regex 不仅能“匹配”（回答 Yes/No），还能“提取”（Extract）和“替换”（Replace），这是数据整理的核心需求。</p>
</li>
</ul>
</li>
</ol>
<p><strong>心智模型：调试是工作流的一部分 (Debugging as a Workflow)</strong></p>
<p>讲师的最后一个建议点明了专业人士如何使用 Regex：<strong>不要猜测，要调试</strong> [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1218">20:18</a>]。Regex 的执行过程对人脑来说是不直观的。因此，使用 Regex 调试器（如 regex101）不是“作弊”或“新手”的标志，而是专业工作流的必要组成部分。它将 Regex 引擎的“黑盒”执行过程“可视化” [<a target="_blank" rel="noopener" href="http://www.youtube.com/watch?v=sz_dsktIjt4&amp;t=1264">21:04</a>]，让你能看到每一步匹配、回溯、捕获组的变化，从而快速定位和修复问题。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a target="_blank" rel="noopener" href="https://github.com/angelysss">Angelysss</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/11/08/Lecture%204_Data%20Wranging/">http://example.com/2025/11/08/Lecture%204_Data%20Wranging/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">None</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Note/">Note</a></div><div class="post-share"><div class="social-share" data-image="/img/avatar.jpg" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="WeChat"/></a><div class="post-qr-code-desc">WeChat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="Alipay"/></a><div class="post-qr-code-desc">Alipay</div></li></ul></div></div><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/11/07/Lecture%201_The%20Shell/" title="Lecture 1_The Shell"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-07</div><div class="info-item-2">Lecture 1_The Shell</div></div><div class="info-2"><div class="info-item-1"> Overview 这堂课（视频）是“计算机教育中缺失的一课 (The Missing Semester of Your CS)”系列的第一讲。它的核心论题是：计算机专业的学生虽然擅长使用计算机来执行重复性任务和构建软件，但却常常忽视了那些能极大提升自己开发效率的工具 [00:34]。本课程旨在弥补这一差距，向学生展示如何充分利用已有的工具、学习新工具，并将它们组合起来，以更高效的方式在日常学习、研究和工作中使用计算机 [01:05]。本讲作为开篇，结论是为后续所有高级工具的学习打下基础，详细介绍最核心的交互界面——Shell（命令行外壳），包括它的工作原理、文件系统导航、权限管理，以及 Shell 最强大的特性：通过“管道”将简单程序组合成复杂的工作流。   按照主题来梳理  1. 课程介绍：我们为什么需要“缺失的一课”？ 本课程的开设源于讲师们（Anish, Jose 和 John）在 MIT 担任助教时的一个观察：绝大多数计算机科学专业的学生，尽管深知计算机在自动化和处理重复任务上的威力，却很少将这种能力应用到自己身上 [00:26]。他们会编写复杂的软件，但自己的开发流程...</div></div></div></a><a class="pagination-related" href="/2025/11/02/Vim/" title="Vim"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-02</div><div class="info-item-2">Vim</div></div><div class="info-2"><div class="info-item-1"> Missing Semester  Modal editing Vim is a modal editor.  Normal: for moving around a files and making edits Insert: for inserting text Command-line: for running a command Replace: for replacing text Visual(plain, line or block): for selecting blocks of text  Keystrokes have different meanings in different operating modes. e.g. x: In Insert mode will just insert a literal character ‘x’, but in Normal mode, it will delete the character under the cursor, and in Visual mode, it will delete the se...</div></div></div></a><a class="pagination-related" href="/2025/11/07/Lecture%202_Shell%20Tools%20and%20Scripting/" title="Lecture 2_Shell Tolls and Scripting"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-07</div><div class="info-item-2">Lecture 2_Shell Tolls and Scripting</div></div><div class="info-2"><div class="info-item-1"> Overview 本视频（Missing Semester 课程的第二讲）的核心论题是，Shell（特别是 Bash）远不止是一个简单的命令执行器，它本身就是一个功能完备且异常强大的编程环境。讲座的结论是，通过掌握 Shell 脚本的核心概念（如变量、控制流、函数）以及学会使用一系列高效的命令行工具（用于查找、搜索和导航），开发者可以将大量重复性的手动任务自动化，从而极大地提升工作效率和能力。  按照主题来梳理  第一节：Shell 脚本编程——释放 Bash 的真正力量 大多数开发者将 Shell 视为执行单个命令的地方，但它的真正潜力在于其“脚本”能力。本节深入探讨了将 Shell (Bash) 作为一种编程语言来使用的核心概念，这是实现自动化的基石。   变量（Variables）   在 Bash 中定义变量非常直接，使用 foo=bar 这样的语法 [01:07]。但这里有一个至关重要的“怪癖”：等号两边绝对不能有空格。   foo = bar [01:33]（注意空格）在 Bash 中不会被解释为变量赋值。相反，Shell 会尝试执行一个名为 foo 的程序，并将其...</div></div></div></a></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#overview"><span class="toc-number">1.</span> <span class="toc-text"> Overview</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%89%E7%85%A7%E4%B8%BB%E9%A2%98%E6%9D%A5%E6%A2%B3%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text"> 按照主题来梳理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98%E4%B8%80%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E6%95%B4%E7%90%86-data-wrangling-%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%BA%90%E5%87%86%E5%A4%87"><span class="toc-number">2.1.</span> <span class="toc-text"> 主题一：什么是数据整理 (Data Wrangling) 与数据源准备</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98%E4%BA%8C%E4%BD%BF%E7%94%A8-sed-%E5%92%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-regular-expressions-%E6%8F%90%E5%8F%96%E5%85%B3%E9%94%AE%E4%BF%A1%E6%81%AF"><span class="toc-number">2.2.</span> <span class="toc-text"> 主题二：使用 sed 和正则表达式 (Regular Expressions) 提取关键信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98%E4%B8%89%E8%81%9A%E5%90%88%E6%95%B0%E6%8D%AE-aggregating-data-sort-unique-%E5%92%8C-awk"><span class="toc-number">2.3.</span> <span class="toc-text"> 主题三：聚合数据 (Aggregating Data) - sort, unique, 和 awk</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E9%A2%98%E5%9B%9B%E6%9B%B4%E5%A4%9A%E9%AB%98%E7%BA%A7%E5%B7%A5%E5%85%B7%E4%B8%8E%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%95%B0%E6%8D%AE%E6%95%B4%E7%90%86"><span class="toc-number">2.4.</span> <span class="toc-text"> 主题四：更多高级工具与二进制数据整理</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A1%86%E6%9E%B6-%E5%BF%83%E6%99%BA%E6%A8%A1%E5%9E%8B-framework-mindset"><span class="toc-number">3.</span> <span class="toc-text"> 框架 &amp; 心智模型 (Framework &amp; Mindset)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%86%E6%9E%B6%E4%B8%80unix-%E5%93%B2%E5%AD%A6%E4%B9%8B%E7%AE%A1%E9%81%93%E4%B8%8E%E8%BF%87%E6%BB%A4%E5%99%A8-the-unix-philosophy-pipeline-and-filters"><span class="toc-number">3.1.</span> <span class="toc-text"> 框架一：UNIX 哲学之“管道与过滤器” (The UNIX Philosophy: “Pipeline and Filters”)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A1%86%E6%9E%B6%E4%BA%8C%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F-regular-expressions-%E6%8F%8F%E8%BF%B0%E6%96%87%E6%9C%AC%E7%9A%84%E9%A2%86%E5%9F%9F%E7%89%B9%E5%AE%9A%E8%AF%AD%E8%A8%80"><span class="toc-number">3.2.</span> <span class="toc-text"> 框架二：正则表达式 (Regular Expressions) - 描述文本的“领域特定语言”</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer" style="background: linear-gradient(20deg, #0062be, #925696, #cc426e, #fb0347);"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By Angelysss</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.1</a></span></div><div class="footer_custom_text">Hi, welcome to my <a target="_blank" rel="noopener" href="https://butterfly.js.org/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.1"></script><script src="/js/main.js?v=5.5.1"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js"></script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/canvas-nest.min.js"></script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/dist/click-heart.min.js" async="async" mobile="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><i class="fas fa-spinner fa-pulse" id="loading-status" hidden="hidden"></i><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="local-search-input"><input placeholder="搜索文章" type="text"/></div><hr/><div id="local-search-results"></div><div class="ais-Pagination" id="local-search-pagination" style="display:none;"><ul class="ais-Pagination-list"></ul></div><div id="local-search-stats"></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.5.1"></script></div></div></body></html>